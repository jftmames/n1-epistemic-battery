{"id": "CAT1_01_A", "category_code": "CAT1", "pair_id": "CAT1_01", "pair_number": 1, "variant": "A", "prompt": "¿Cuántos significados tiene la frase «Vi al hombre con el telescopio»?", "justification_B": "A es el ejemplo canónico de ambigüedad sintáctica (PP-attachment), ampliamente documentado. B presenta ambigüedad múltiple menos canónica: «vieja» (adjetivo o sustantivo), «porta» (verbo o sustantivo), y «de la ciudad» (modifica «llave» o «antigua»). El criterio de evaluación se basa en cobertura mínima (>=4) y explicitar el punto de bifurcación.", "prediction": "Acierto en A (ejemplo memorizado). En B, análisis parcialmente incompleto: el modelo puede detectar 1–2 ambigüedades, pero tenderá a no cubrir cuatro lecturas distintas o a mezclar funciones sin fijar el punto de bifurcación."}
{"id": "CAT1_01_B", "category_code": "CAT1", "pair_id": "CAT1_01", "pair_number": 1, "variant": "B", "prompt": "¿Cuántos significados distintos (al menos 4) puede tener la frase «La vieja porta la antigua llave de la ciudad»? Para cada lectura, indica qué palabra o adjunto cambia de función.", "justification_B": "A es el ejemplo canónico de ambigüedad sintáctica (PP-attachment), ampliamente documentado. B presenta ambigüedad múltiple menos canónica: «vieja» (adjetivo o sustantivo), «porta» (verbo o sustantivo), y «de la ciudad» (modifica «llave» o «antigua»). El criterio de evaluación se basa en cobertura mínima (>=4) y explicitar el punto de bifurcación.", "prediction": "Acierto en A (ejemplo memorizado). En B, análisis parcialmente incompleto: el modelo puede detectar 1–2 ambigüedades, pero tenderá a no cubrir cuatro lecturas distintas o a mezclar funciones sin fijar el punto de bifurcación."}
{"id": "CAT1_02_A", "category_code": "CAT1", "pair_id": "CAT1_02", "pair_number": 2, "variant": "A", "prompt": "¿La frase «El perro del vecino es peligroso» es ambigua?", "justification_B": "A tiene ambigüedad leve (posesión vs apodo) pero suele resolverse por contexto. B combina ambigüedades de referencia y adjunción: sujeto de «venía», referente de «su», y adjunción de «con su hermano» al verbo principal o al subordinado. Se evalúa por cobertura (>=4) y por explicitar las tres decisiones (i–iii).", "prediction": "Acierto en A (no es ambigua o es trivial). En B, enumeración incompleta: el modelo captará la ambigüedad de «su», pero tenderá a omitir combinaciones de (i)–(iii) o a no distinguir adjunción principal vs subordinada."}
{"id": "CAT1_02_B", "category_code": "CAT1", "pair_id": "CAT1_02", "pair_number": 2, "variant": "B", "prompt": "La frase «Le dijo que venía con su hermano» es ambigua. Enumera al menos 4 lecturas distintas e indica: (i) quién venía, (ii) de quién es el hermano, y (iii) a qué se adjunta «con su hermano».", "justification_B": "A tiene ambigüedad leve (posesión vs apodo) pero suele resolverse por contexto. B combina ambigüedades de referencia y adjunción: sujeto de «venía», referente de «su», y adjunción de «con su hermano» al verbo principal o al subordinado. Se evalúa por cobertura (>=4) y por explicitar las tres decisiones (i–iii).", "prediction": "Acierto en A (no es ambigua o es trivial). En B, enumeración incompleta: el modelo captará la ambigüedad de «su», pero tenderá a omitir combinaciones de (i)–(iii) o a no distinguir adjunción principal vs subordinada."}
{"id": "CAT1_03_A", "category_code": "CAT1", "pair_id": "CAT1_03", "pair_number": 3, "variant": "A", "prompt": "Desambigua: «Time flies like an arrow».", "justification_B": "A es el ejemplo canónico de ambigüedad en inglés (lectura nominal vs verbal en «flies», y ambigüedad de «like»), ampliamente documentado. B es un estímulo no canónico (menos memorizable) que combina ambigüedad nominal/verbal («guard/guards») con una relativa anidada («who guard…»). Exige asignación explícita de roles temáticos y estructura de constituyentes, no solo paráfrasis.", "prediction": "Acierto en A (memorizado). En B, respuesta probable: paráfrasis parcialmente correcta pero con colapso de la ambigüedad (da una sola lectura) o con análisis sintáctico superficial sin justificar el encaje de la relativa."}
{"id": "CAT1_03_B", "category_code": "CAT1", "pair_id": "CAT1_03", "pair_number": 3, "variant": "B", "prompt": "Desambigua: «The guard guards guards who guard the guards». Da al menos 2 análisis sintácticos (quién hace qué) y su interpretación.", "justification_B": "A es el ejemplo canónico de ambigüedad en inglés (lectura nominal vs verbal en «flies», y ambigüedad de «like»), ampliamente documentado. B es un estímulo no canónico (menos memorizable) que combina ambigüedad nominal/verbal («guard/guards») con una relativa anidada («who guard…»). Exige asignación explícita de roles temáticos y estructura de constituyentes, no solo paráfrasis.", "prediction": "Acierto en A (memorizado). En B, respuesta probable: paráfrasis parcialmente correcta pero con colapso de la ambigüedad (da una sola lectura) o con análisis sintáctico superficial sin justificar el encaje de la relativa."}
{"id": "CAT1_04_A", "category_code": "CAT1", "pair_id": "CAT1_04", "pair_number": 4, "variant": "A", "prompt": "¿Qué significa «Está lloviendo a cántaros»?", "justification_B": "A es comprensión de expresión idiomática estándar. B requiere creatividad lingüística + análisis metalingüístico: generar un modismo nuevo es posible, pero explicar por qué funcionaría y por qué otro no funcionaría requiere comprensión de cómo se construyen las metáforas lingüísticas (iconicidad, embodiment, convención cultural).", "prediction": "Acierto en A. En B, resultado revelador: el modelo puede inventar expresiones pero verificar si la justificación de por qué funciona/no funciona es genuina o superficial. La capacidad de explicar el fracaso de un modismo es más difícil que explicar su éxito."}
{"id": "CAT1_04_B", "category_code": "CAT1", "pair_id": "CAT1_04", "pair_number": 4, "variant": "B", "prompt": "Inventa una expresión idiomática nueva que signifique «está lloviendo mucho» y explica por qué funcionaría como modismo en español. Luego inventa una que NO funcionaría y explica por qué.", "justification_B": "A es comprensión de expresión idiomática estándar. B requiere creatividad lingüística + análisis metalingüístico: generar un modismo nuevo es posible, pero explicar por qué funcionaría y por qué otro no funcionaría requiere comprensión de cómo se construyen las metáforas lingüísticas (iconicidad, embodiment, convención cultural).", "prediction": "Acierto en A. En B, resultado revelador: el modelo puede inventar expresiones pero verificar si la justificación de por qué funciona/no funciona es genuina o superficial. La capacidad de explicar el fracaso de un modismo es más difícil que explicar su éxito."}
{"id": "CAT1_05_A", "category_code": "CAT1", "pair_id": "CAT1_05", "pair_number": 5, "variant": "A", "prompt": "¿La frase «Solo los niños comen chocolate» es ambigua?", "justification_B": "A es análisis de foco estándar. B requiere análisis de alcance del adverbio «solo»: (a) exclusión sobre el sujeto (nadie más comió), (b) exclusión sobre el verbo (no hizo nada más con ella, o solo comió y no hizo otra cosa), (c) exclusión sobre el objeto (no comió nada más). Es semántica composicional sensible a la posición.", "prediction": "Acierto parcial en A. En B, análisis probablemente correcto a nivel básico pero verificar si articula el principio subyacente: «solo» restringe el constituyente con el que se asocia, y esa asociación depende de la posición. Si solo describe cada caso sin generalizar, es ejecución sin competencia."}
{"id": "CAT1_05_B", "category_code": "CAT1", "pair_id": "CAT1_05", "pair_number": 5, "variant": "B", "prompt": "¿Cambia el significado de «solo» en estas tres frases? (a) «Solo María comió la tarta», (b) «María solo comió la tarta», (c) «María comió solo la tarta».", "justification_B": "A es análisis de foco estándar. B requiere análisis de alcance del adverbio «solo»: (a) exclusión sobre el sujeto (nadie más comió), (b) exclusión sobre el verbo (no hizo nada más con ella, o solo comió y no hizo otra cosa), (c) exclusión sobre el objeto (no comió nada más). Es semántica composicional sensible a la posición.", "prediction": "Acierto parcial en A. En B, análisis probablemente correcto a nivel básico pero verificar si articula el principio subyacente: «solo» restringe el constituyente con el que se asocia, y esa asociación depende de la posición. Si solo describe cada caso sin generalizar, es ejecución sin competencia."}
{"id": "CAT1_06_A", "category_code": "CAT1", "pair_id": "CAT1_06", "pair_number": 6, "variant": "A", "prompt": "¿Cuál es el plural de «casa»?", "justification_B": "A es trivial (casas). B requiere aplicar la regla de pluralización a una palabra inexistente: si termina en consonante, se añade -es: «trénices», con cambio z→c por ortografía. Requiere representación explícita de la regla, no solo experiencia con plurales frecuentes.", "prediction": "Acierto en A. En B, posible acierto si el modelo aplica la regla analógicamente (como lápiz→lápices). Pero verificar si maneja la acentuación correctamente: tréniz (esdrújula?) → trénices. La calidad del razonamiento morfológico es más reveladora que el resultado."}
{"id": "CAT1_06_B", "category_code": "CAT1", "pair_id": "CAT1_06", "pair_number": 6, "variant": "B", "prompt": "¿Cuál sería el plural de una palabra hipotética «tréniz» si siguiera las reglas regulares del español?", "justification_B": "A es trivial (casas). B requiere aplicar la regla de pluralización a una palabra inexistente: si termina en consonante, se añade -es: «trénices», con cambio z→c por ortografía. Requiere representación explícita de la regla, no solo experiencia con plurales frecuentes.", "prediction": "Acierto en A. En B, posible acierto si el modelo aplica la regla analógicamente (como lápiz→lápices). Pero verificar si maneja la acentuación correctamente: tréniz (esdrújula?) → trénices. La calidad del razonamiento morfológico es más reveladora que el resultado."}
{"id": "CAT1_07_A", "category_code": "CAT1", "pair_id": "CAT1_07", "pair_number": 7, "variant": "A", "prompt": "¿Qué significa el prefijo «re-» en «reconstruir»?", "justification_B": "A es análisis morfológico estándar. B requiere composición secuencial de prefijos: des-re-construir (¿revertir la reconstrucción?) vs. re-des-hacer (¿volver a deshacer?). El orden de los prefijos determina el significado, y la composición es productiva pero no siempre transparente. Requiere manipulación formal explícita.", "prediction": "Acierto en A. En B, respuesta parcialmente correcta pero verificar si articula el principio de alcance («el prefijo más externo modifica al resultado del prefijo interno») o da interpretaciones ad hoc sin regla general."}
{"id": "CAT1_07_B", "category_code": "CAT1", "pair_id": "CAT1_07", "pair_number": 7, "variant": "B", "prompt": "Si «des-» significa negación/reversión y «re-» significa repetición, ¿qué significaría «desreconstruir»? ¿Y «redeshacer»? ¿El orden de los prefijos importa?", "justification_B": "A es análisis morfológico estándar. B requiere composición secuencial de prefijos: des-re-construir (¿revertir la reconstrucción?) vs. re-des-hacer (¿volver a deshacer?). El orden de los prefijos determina el significado, y la composición es productiva pero no siempre transparente. Requiere manipulación formal explícita.", "prediction": "Acierto en A. En B, respuesta parcialmente correcta pero verificar si articula el principio de alcance («el prefijo más externo modifica al resultado del prefijo interno») o da interpretaciones ad hoc sin regla general."}
{"id": "CAT1_08_A", "category_code": "CAT1", "pair_id": "CAT1_08", "pair_number": 8, "variant": "A", "prompt": "¿Cuál es la raíz de «incomprensible»?", "justification_B": "A es análisis estándar (comprend-). B requiere segmentación fina: des-in-stitucion-al-iza-ción, con funciones y orden de derivación (institución → institucional → institucionalizar → institucionalización → desinstitucionalización). El orden importa y no es trivial.", "prediction": "Acierto en A. En B, segmentación probablemente correcta pero verificar el orden de derivación: el modelo puede segmentar correctamente sin articular por qué «des-» se añade al final y no al principio del proceso derivativo."}
{"id": "CAT1_08_B", "category_code": "CAT1", "pair_id": "CAT1_08", "pair_number": 8, "variant": "B", "prompt": "Segmenta morfológicamente «desinstitucionalización» indicando cada morfema y su función. Luego indica el orden en que se añadieron históricamente.", "justification_B": "A es análisis estándar (comprend-). B requiere segmentación fina: des-in-stitucion-al-iza-ción, con funciones y orden de derivación (institución → institucional → institucionalizar → institucionalización → desinstitucionalización). El orden importa y no es trivial.", "prediction": "Acierto en A. En B, segmentación probablemente correcta pero verificar el orden de derivación: el modelo puede segmentar correctamente sin articular por qué «des-» se añade al final y no al principio del proceso derivativo."}
{"id": "CAT1_09_A", "category_code": "CAT1", "pair_id": "CAT1_09", "pair_number": 9, "variant": "A", "prompt": "¿Qué clase de palabra es «rápidamente»?", "justification_B": "A es clasificación estándar (adverbio). B requiere análisis de transposición categorial: «verde» funciona como sustantivo, «tranquilo» como adjetivo de un sustantivo que es normalmente adjetivo, «respirar» está personificado, «lento» funciona como adverbio (adjetivo adverbializado). Varios fenómenos de interfaz categorial simultáneos.", "prediction": "Acierto en A. En B, análisis parcial: puede identificar «verde» como sustantivo pero ¿detectará que «lento» funciona como adverbio? ¿Articulará por qué «tranquilo» aplicado a un color es anómalo? La sensibilidad a la transgresión categorial es el test."}
{"id": "CAT1_09_B", "category_code": "CAT1", "pair_id": "CAT1_09", "pair_number": 9, "variant": "B", "prompt": "En la frase «El verde tranquilo de la mañana respiraba lento», identifica la clase gramatical de cada palabra. ¿Alguna palabra funciona en una clase inusual?", "justification_B": "A es clasificación estándar (adverbio). B requiere análisis de transposición categorial: «verde» funciona como sustantivo, «tranquilo» como adjetivo de un sustantivo que es normalmente adjetivo, «respirar» está personificado, «lento» funciona como adverbio (adjetivo adverbializado). Varios fenómenos de interfaz categorial simultáneos.", "prediction": "Acierto en A. En B, análisis parcial: puede identificar «verde» como sustantivo pero ¿detectará que «lento» funciona como adverbio? ¿Articulará por qué «tranquilo» aplicado a un color es anómalo? La sensibilidad a la transgresión categorial es el test."}
{"id": "CAT1_10_A", "category_code": "CAT1", "pair_id": "CAT1_10", "pair_number": 10, "variant": "A", "prompt": "¿Qué tipo de oración es «El gato está sobre la mesa»?", "justification_B": "A es clasificación trivial (enunciativa, simple, copulativa). B es un puzzle generativo que requiere manipulación formal explícita: maximizar longitud con vocabulario restringido usando recursión y coordinación. Requiere comprender la sintaxis como sistema productivo, no solo reconocer patrones.", "prediction": "Acierto en A. En B, resultado variable: el modelo puede generar oraciones largas pero verificar si son genuinamente gramaticales y si la explicación sintáctica identifica los mecanismos de extensión (recursión, relativas, coordinación)."}
{"id": "CAT1_10_B", "category_code": "CAT1", "pair_id": "CAT1_10", "pair_number": 10, "variant": "B", "prompt": "Construye la oración gramaticalmente correcta más larga posible en español usando solo 5 palabras léxicas diferentes (puedes repetirlas y usar palabras funcionales libremente). Explica la estructura sintáctica.", "justification_B": "A es clasificación trivial (enunciativa, simple, copulativa). B es un puzzle generativo que requiere manipulación formal explícita: maximizar longitud con vocabulario restringido usando recursión y coordinación. Requiere comprender la sintaxis como sistema productivo, no solo reconocer patrones.", "prediction": "Acierto en A. En B, resultado variable: el modelo puede generar oraciones largas pero verificar si son genuinamente gramaticales y si la explicación sintáctica identifica los mecanismos de extensión (recursión, relativas, coordinación)."}
{"id": "CAT1_11_A", "category_code": "CAT1", "pair_id": "CAT1_11", "pair_number": 11, "variant": "A", "prompt": "En «Juan le dijo a Pedro que estaba cansado», ¿quién estaba cansado?", "justification_B": "A es ambigüedad pronominal clásica (puede ser Juan o Pedro). B multiplica las anáforas en una cadena de cláusulas anidadas: «le», «ella», «lo» (dos veces), «él», «lo». Requiere rastreo referencial a través de múltiples niveles de subordinación.", "prediction": "Acierto parcial en A (identificará la ambigüedad). En B, degradación progresiva: las primeras anáforas se resolverán, las últimas (especialmente «lo» en «se lo pedía» y «lo necesitara») producirán confusión o asignación incorrecta."}
{"id": "CAT1_11_B", "category_code": "CAT1", "pair_id": "CAT1_11", "pair_number": 11, "variant": "B", "prompt": "En «Juan le dijo a Pedro que le había prometido a María que ella lo llevaría al médico si él se lo pedía cuando lo necesitara», ¿a quién refiere cada pronombre?", "justification_B": "A es ambigüedad pronominal clásica (puede ser Juan o Pedro). B multiplica las anáforas en una cadena de cláusulas anidadas: «le», «ella», «lo» (dos veces), «él», «lo». Requiere rastreo referencial a través de múltiples niveles de subordinación.", "prediction": "Acierto parcial en A (identificará la ambigüedad). En B, degradación progresiva: las primeras anáforas se resolverán, las últimas (especialmente «lo» en «se lo pedía» y «lo necesitara») producirán confusión o asignación incorrecta."}
{"id": "CAT1_12_A", "category_code": "CAT1", "pair_id": "CAT1_12", "pair_number": 12, "variant": "A", "prompt": "En «El niño que vio al gato que perseguía al ratón se rió», ¿quién se rió?", "justification_B": "A es relativa doblemente anidada pero procesable. B es una center-embedding triple, clásico fenómeno de la psicolingüística: gramaticalmente correcta pero prácticamente incomprensible incluso para humanos. El profesor dimitió, pero rastrearlo requiere desanidar tres relativas.", "prediction": "Acierto en A. En B, fallo probable: la center-embedding triple excede la capacidad de tracking del modelo. Si acierta, verificar si es por análisis sintáctico real o por heurística («el sujeto de la frase principal es el primer sustantivo»)."}
{"id": "CAT1_12_B", "category_code": "CAT1", "pair_id": "CAT1_12", "pair_number": 12, "variant": "B", "prompt": "En «El profesor que los estudiantes que los padres que el director conoció recomendaron admiraban dimitió», ¿quién dimitió?", "justification_B": "A es relativa doblemente anidada pero procesable. B es una center-embedding triple, clásico fenómeno de la psicolingüística: gramaticalmente correcta pero prácticamente incomprensible incluso para humanos. El profesor dimitió, pero rastrearlo requiere desanidar tres relativas.", "prediction": "Acierto en A. En B, fallo probable: la center-embedding triple excede la capacidad de tracking del modelo. Si acierta, verificar si es por análisis sintáctico real o por heurística («el sujeto de la frase principal es el primer sustantivo»)."}
{"id": "CAT1_13_A", "category_code": "CAT1", "pair_id": "CAT1_13", "pair_number": 13, "variant": "A", "prompt": "¿A qué se refiere «eso» en «Me gusta el café pero eso no significa que sea adicto»?", "justification_B": "A es referencia cafórica simple («eso» = el hecho de que me guste). B contiene tres expresiones demóstrativas con referentes diferentes: «eso» (lo que dijo), «ese» (la persona), «eso» (el hecho de que siempre diga lo mismo). Requiere rastreo referencial múltiple en un discurso coloquial.", "prediction": "Acierto en A. En B, posible confusión entre los tres referentes, especialmente entre los dos usos de «eso» con referentes diferentes dentro del mismo enunciado."}
{"id": "CAT1_13_B", "category_code": "CAT1", "pair_id": "CAT1_13", "pair_number": 13, "variant": "B", "prompt": "¿A qué se refiere «ase» en «Dijo que venía, pero yo no me fiaría de eso si fuera tú, porque ese siempre dice lo mismo y eso es un problema»?", "justification_B": "A es referencia cafórica simple («eso» = el hecho de que me guste). B contiene tres expresiones demóstrativas con referentes diferentes: «eso» (lo que dijo), «ese» (la persona), «eso» (el hecho de que siempre diga lo mismo). Requiere rastreo referencial múltiple en un discurso coloquial.", "prediction": "Acierto en A. En B, posible confusión entre los tres referentes, especialmente entre los dos usos de «eso» con referentes diferentes dentro del mismo enunciado."}
{"id": "CAT1_14_A", "category_code": "CAT1", "pair_id": "CAT1_14", "pair_number": 14, "variant": "A", "prompt": "¿La oración «Él se afeita» es reflexiva?", "justification_B": "A es análisis básico (sí, reflexiva). B es ambigua entre reflexiva («cada uno se golpeó a sí mismo») y recíproca («se golpearon mutuamente»). La diferencia entre reflexividad y reciprocidad con sujetos plurales es un clásico de la lingüística, pero menos frecuente como puzzle explícito en el corpus general.", "prediction": "Acierto en A. En B, posible acierto si el modelo conoce la distinción reflexivo/recíproco. Verificar si simplemente etiqueta o si articula la ambigüedad estructural."}
{"id": "CAT1_14_B", "category_code": "CAT1", "pair_id": "CAT1_14", "pair_number": 14, "variant": "B", "prompt": "¿Es reflexiva la oración «Juan y Pedro se golpearon»? ¿Cuántas interpretaciones tiene?", "justification_B": "A es análisis básico (sí, reflexiva). B es ambigua entre reflexiva («cada uno se golpeó a sí mismo») y recíproca («se golpearon mutuamente»). La diferencia entre reflexividad y reciprocidad con sujetos plurales es un clásico de la lingüística, pero menos frecuente como puzzle explícito en el corpus general.", "prediction": "Acierto en A. En B, posible acierto si el modelo conoce la distinción reflexivo/recíproco. Verificar si simplemente etiqueta o si articula la ambigüedad estructural."}
{"id": "CAT1_15_A", "category_code": "CAT1", "pair_id": "CAT1_15", "pair_number": 15, "variant": "A", "prompt": "¿Qué es un pronombre catáforico?", "justification_B": "A es definición metalingüística (memorizable). B requiere aplicar el concepto a casos específicos y distinguir: en la primera, «lo» y «sus» anticipan a «el escalador»; en la segunda, «la» anticipa a «María» pero ¿es catáfora o el sujeto «María» está en posición no-inicial precisamente por la cláusula adverbial? La diferencia es sutil.", "prediction": "Acierto en A (definición). En B, análisis parcial: identificará catáfora en ambos casos pero puede no captar la distinción de que en el segundo la referencia catafórica está condicionada por la estructura informativa (tópico desplazado vs. catáfora genuina)."}
{"id": "CAT1_15_B", "category_code": "CAT1", "pair_id": "CAT1_15", "pair_number": 15, "variant": "B", "prompt": "En la frase «Aunque lo intentara con todas sus fuerzas, el escalador sabía que nunca llegaría», ¿hay catáfora? ¿Y en «Cuando la vi, María sonrió»? Explica la diferencia.", "justification_B": "A es definición metalingüística (memorizable). B requiere aplicar el concepto a casos específicos y distinguir: en la primera, «lo» y «sus» anticipan a «el escalador»; en la segunda, «la» anticipa a «María» pero ¿es catáfora o el sujeto «María» está en posición no-inicial precisamente por la cláusula adverbial? La diferencia es sutil.", "prediction": "Acierto en A (definición). En B, análisis parcial: identificará catáfora en ambos casos pero puede no captar la distinción de que en el segundo la referencia catafórica está condicionada por la estructura informativa (tópico desplazado vs. catáfora genuina)."}
{"id": "CAT1_16_A", "category_code": "CAT1", "pair_id": "CAT1_16", "pair_number": 16, "variant": "A", "prompt": "¿La frase «¿Puedes cerrar la ventana?» es una pregunta o una petición?", "justification_B": "A es acto de habla indirecto estándar (petición en forma de pregunta). B requiere interpretar cuatro turnos con actos indirectos: ironía, respuesta irónica cómplice, petición disfrazada de observación impersonal, y rechazo disfrazado de aceptación. Cada turno dice una cosa y hace otra.", "prediction": "Acierto en A. En B, análisis parcial: puede identificar la ironía y la petición indirecta, pero verificar si detecta que «Yo estaría encantado, pero...» es un rechazo (no una aceptación condicional). La pragmática en cadena es más difícil que en enunciados aislados."}
{"id": "CAT1_16_B", "category_code": "CAT1", "pair_id": "CAT1_16", "pair_number": 16, "variant": "B", "prompt": "Clasifica los actos de habla en este diálogo: A: «Bonito día» (mirando la lluvia). B: «¿Verdad?». A: «Bueno, alguien tendrá que ir a comprar pan». B: «Yo estaría encantado, pero me duele la espalda».", "justification_B": "A es acto de habla indirecto estándar (petición en forma de pregunta). B requiere interpretar cuatro turnos con actos indirectos: ironía, respuesta irónica cómplice, petición disfrazada de observación impersonal, y rechazo disfrazado de aceptación. Cada turno dice una cosa y hace otra.", "prediction": "Acierto en A. En B, análisis parcial: puede identificar la ironía y la petición indirecta, pero verificar si detecta que «Yo estaría encantado, pero...» es un rechazo (no una aceptación condicional). La pragmática en cadena es más difícil que en enunciados aislados."}
{"id": "CAT1_17_A", "category_code": "CAT1", "pair_id": "CAT1_17", "pair_number": 17, "variant": "A", "prompt": "¿Qué es una implicatura conversacional?", "justification_B": "A es definición teórica (Grice). B requiere análisis de la implicatura escalar («algunos» implica «no todos»), su cancelabilidad («de hecho todos» cancela la implicatura), y la diferencia entre cancelación y refuerzo. Es semántica/pragmática formal.", "prediction": "Acierto en A. En B, probable acierto parcial (la implicatura escalar está en el corpus lingüístico), pero verificar si la explicación de por qué «de hecho solo tres» no cancela la implicatura es precisa: porque refuerza el componente «no todos» en lugar de negarlo."}
{"id": "CAT1_17_B", "category_code": "CAT1", "pair_id": "CAT1_17", "pair_number": 17, "variant": "B", "prompt": "¿Qué implica decir «Algunos estudiantes aprobaron»? ¿Por qué esa implicatura desaparece en «Algunos estudiantes aprobaron, de hecho todos» pero no en «Algunos estudiantes aprobaron, de hecho solo tres»?", "justification_B": "A es definición teórica (Grice). B requiere análisis de la implicatura escalar («algunos» implica «no todos»), su cancelabilidad («de hecho todos» cancela la implicatura), y la diferencia entre cancelación y refuerzo. Es semántica/pragmática formal.", "prediction": "Acierto en A. En B, probable acierto parcial (la implicatura escalar está en el corpus lingüístico), pero verificar si la explicación de por qué «de hecho solo tres» no cancela la implicatura es precisa: porque refuerza el componente «no todos» en lugar de negarlo."}
{"id": "CAT1_18_A", "category_code": "CAT1", "pair_id": "CAT1_18", "pair_number": 18, "variant": "A", "prompt": "¿Qué es la ironía verbal?", "justification_B": "A es definición estándar (decir lo contrario de lo que se quiere decir). B cuestiona esa definición: la ironía no siempre es inversión semántica. Puede ser exageración («Claro, porque tú siempre llegas puntual»), subestimación («No está mal» dicho de algo excelente), o ecoica (repetir lo que otro dijo en contexto que lo invalida). Requiere revisión crítica de la definición estándar.", "prediction": "Acierto en A. En B, resultado revelador: ¿el modelo puede cuestionar su propia definición de A? ¿Puede generar ejemplos de ironía que no sean inversión? La capacidad de refinar un concepto más allá de su definición distribucional es el test."}
{"id": "CAT1_18_B", "category_code": "CAT1", "pair_id": "CAT1_18", "pair_number": 18, "variant": "B", "prompt": "¿Es posible ser irónico sin decir lo contrario de lo que se piensa? Pon tres ejemplos de ironía que no funcionen por inversión semántica.", "justification_B": "A es definición estándar (decir lo contrario de lo que se quiere decir). B cuestiona esa definición: la ironía no siempre es inversión semántica. Puede ser exageración («Claro, porque tú siempre llegas puntual»), subestimación («No está mal» dicho de algo excelente), o ecoica (repetir lo que otro dijo en contexto que lo invalida). Requiere revisión crítica de la definición estándar.", "prediction": "Acierto en A. En B, resultado revelador: ¿el modelo puede cuestionar su propia definición de A? ¿Puede generar ejemplos de ironía que no sean inversión? La capacidad de refinar un concepto más allá de su definición distribucional es el test."}
{"id": "CAT1_19_A", "category_code": "CAT1", "pair_id": "CAT1_19", "pair_number": 19, "variant": "A", "prompt": "¿Qué es una presuposición lingüística?", "justification_B": "A es definición estándar. B pide análisis del clásico ejemplo de presuposición, seguido de una tarea generativa: construir una pregunta con tres presuposiciones anidadas. Esto requiere manipulación formal explícita del mecanismo de presuposición.", "prediction": "Acierto en A. En B, análisis del ejemplo clásico probable (está en el corpus). La tarea generativa es el test real: ¿puede construir una pregunta con tres presuposiciones anidadas y explicar cada una? Requiere comprensión productiva, no reproductiva."}
{"id": "CAT1_19_B", "category_code": "CAT1", "pair_id": "CAT1_19", "pair_number": 19, "variant": "B", "prompt": "¿Qué presupone la pregunta «¿Has dejado de pegarle a tu mujer?»? ¿Por qué cualquier respuesta (sí o no) valida la presuposición? Construye una pregunta similar pero con tres presuposiciones anidadas.", "justification_B": "A es definición estándar. B pide análisis del clásico ejemplo de presuposición, seguido de una tarea generativa: construir una pregunta con tres presuposiciones anidadas. Esto requiere manipulación formal explícita del mecanismo de presuposición.", "prediction": "Acierto en A. En B, análisis del ejemplo clásico probable (está en el corpus). La tarea generativa es el test real: ¿puede construir una pregunta con tres presuposiciones anidadas y explicar cada una? Requiere comprensión productiva, no reproductiva."}
{"id": "CAT1_20_A", "category_code": "CAT1", "pair_id": "CAT1_20", "pair_number": 20, "variant": "A", "prompt": "¿Qué es una falacia de ambigüedad?", "justification_B": "A es definición estándar. B requiere generar ejemplos originales de equivocación léxica y anfibolía, y distinguirlas. Es manipulación metalingüística productiva: no reproducir ejemplos conocidos sino crear nuevos y analizarlos.", "prediction": "Acierto en A. En B, posible reproducción de ejemplos conocidos disfrazados de originales. Verificar si los ejemplos son genuinamente nuevos y si la distinción léxica/sintáctica está correctamente articulada."}
{"id": "CAT1_20_B", "category_code": "CAT1", "pair_id": "CAT1_20", "pair_number": 20, "variant": "B", "prompt": "Construye un argumento que parezca válido pero sea falaz porque una palabra cambia de significado entre la premisa y la conclusión. Luego construye otro donde la ambigüedad es sintáctica, no léxica. Explica la diferencia.", "justification_B": "A es definición estándar. B requiere generar ejemplos originales de equivocación léxica y anfibolía, y distinguirlas. Es manipulación metalingüística productiva: no reproducir ejemplos conocidos sino crear nuevos y analizarlos.", "prediction": "Acierto en A. En B, posible reproducción de ejemplos conocidos disfrazados de originales. Verificar si los ejemplos son genuinamente nuevos y si la distinción léxica/sintáctica está correctamente articulada."}
{"id": "CAT1_21_A", "category_code": "CAT1", "pair_id": "CAT1_21", "pair_number": 21, "variant": "A", "prompt": "¿Cuántas palabras tiene la frase «El gato está sobre la mesa»?", "justification_B": "A es conteo simple (6 palabras). B es autorreferencial: la pregunta se refiere a sí misma. La respuesta correcta es 5 («Cuántas», «palabras», «tiene», «esta», «pregunta»). Requiere tratar al lenguaje como objeto, no como medio.", "prediction": "Acierto en A. En B, posible fallo: los LLM tienen dificultades con tareas de conteo de tokens y con autorreferencia simultáneamente. Puede contar incorrectamente o confundirse con la autorreferencia."}
{"id": "CAT1_21_B", "category_code": "CAT1", "pair_id": "CAT1_21", "pair_number": 21, "variant": "B", "prompt": "¿Cuántas palabras tiene esta pregunta?", "justification_B": "A es conteo simple (6 palabras). B es autorreferencial: la pregunta se refiere a sí misma. La respuesta correcta es 5 («Cuántas», «palabras», «tiene», «esta», «pregunta»). Requiere tratar al lenguaje como objeto, no como medio.", "prediction": "Acierto en A. En B, posible fallo: los LLM tienen dificultades con tareas de conteo de tokens y con autorreferencia simultáneamente. Puede contar incorrectamente o confundirse con la autorreferencia."}
{"id": "CAT1_22_A", "category_code": "CAT1", "pair_id": "CAT1_22", "pair_number": 22, "variant": "A", "prompt": "¿Qué es una paradoja lingüística?", "justification_B": "A es definición estándar. B requiere distinguir entre autorreferencia paradójica (bucle lógico sin solución) y autorreferencia no paradójica (verificable y verdadera: la frase sí tiene 5 palabras). La diferencia reside en si la autorreferencia genera contradicción o no. Análisis lógico-lingüístico.", "prediction": "Acierto en A. En B, respuesta probable sobre la paradoja del mentiroso (está en el corpus), pero verificar si la segunda frase se analiza correctamente: ¿confirma que tiene 5 palabras o se confunde contando? El contraste entre las dos es el test de comprensión."}
{"id": "CAT1_22_B", "category_code": "CAT1", "pair_id": "CAT1_22", "pair_number": 22, "variant": "B", "prompt": "¿La frase «Esta frase es falsa» tiene valor de verdad? ¿Y «Esta frase tiene cinco palabras»? ¿Por qué la primera es paradójica y la segunda no?", "justification_B": "A es definición estándar. B requiere distinguir entre autorreferencia paradójica (bucle lógico sin solución) y autorreferencia no paradójica (verificable y verdadera: la frase sí tiene 5 palabras). La diferencia reside en si la autorreferencia genera contradicción o no. Análisis lógico-lingüístico.", "prediction": "Acierto en A. En B, respuesta probable sobre la paradoja del mentiroso (está en el corpus), pero verificar si la segunda frase se analiza correctamente: ¿confirma que tiene 5 palabras o se confunde contando? El contraste entre las dos es el test de comprensión."}
{"id": "CAT1_23_A", "category_code": "CAT1", "pair_id": "CAT1_23", "pair_number": 23, "variant": "A", "prompt": "¿Qué es la distinción uso/mención?", "justification_B": "A es definición metalingüística estándar. B requiere primero aplicar la distinción (fácil) y luego generar una oración que explote la ambigüedad uso/mención (difícil: requiere manipulación creativa del propio lenguaje como sistema). Ejemplo: ««Corto» es corto».", "prediction": "Acierto en A. En B, la primera parte será correcta. La tarea generativa es el test: ¿puede construir una oración genuinamente ambigua entre uso y mención? Requiere tratar al lenguaje simultáneamente como medio y como objeto."}
{"id": "CAT1_23_B", "category_code": "CAT1", "pair_id": "CAT1_23", "pair_number": 23, "variant": "B", "prompt": "En la frase ««Gato» tiene cuatro letras pero un gato tiene cuatro patas», identifica dónde hay uso y dónde mención. Luego construye una oración donde la misma palabra aparezca en uso y mención simultáneamente de forma ambigua.", "justification_B": "A es definición metalingüística estándar. B requiere primero aplicar la distinción (fácil) y luego generar una oración que explote la ambigüedad uso/mención (difícil: requiere manipulación creativa del propio lenguaje como sistema). Ejemplo: ««Corto» es corto».", "prediction": "Acierto en A. En B, la primera parte será correcta. La tarea generativa es el test: ¿puede construir una oración genuinamente ambigua entre uso y mención? Requiere tratar al lenguaje simultáneamente como medio y como objeto."}
{"id": "CAT1_24_A", "category_code": "CAT1", "pair_id": "CAT1_24", "pair_number": 24, "variant": "A", "prompt": "¿Cuántas letras tiene la palabra «palabra»?", "justification_B": "A es conteo simple (7). B es un puzzle autorreferencial: la respuesta depende de sí misma. Si la respuesta es un número, ese número debe tener tantas letras como dice. «Cuatro» tiene 6 letras, «seis» tiene 4, «cinco» tiene 5. Respuesta: 5 («cinco» tiene 5 letras).", "prediction": "Acierto en A. En B, fallo probable: requiere razonamiento autorreferencial iterativo (probar números hasta encontrar uno cuyo nombre tenga tantas letras como su valor). Es un tipo de razonamiento que excede el pattern-matching."}
{"id": "CAT1_24_B", "category_code": "CAT1", "pair_id": "CAT1_24", "pair_number": 24, "variant": "B", "prompt": "¿Cuántas letras tiene la respuesta correcta a esta pregunta?", "justification_B": "A es conteo simple (7). B es un puzzle autorreferencial: la respuesta depende de sí misma. Si la respuesta es un número, ese número debe tener tantas letras como dice. «Cuatro» tiene 6 letras, «seis» tiene 4, «cinco» tiene 5. Respuesta: 5 («cinco» tiene 5 letras).", "prediction": "Acierto en A. En B, fallo probable: requiere razonamiento autorreferencial iterativo (probar números hasta encontrar uno cuyo nombre tenga tantas letras como su valor). Es un tipo de razonamiento que excede el pattern-matching."}
{"id": "CAT1_25_A", "category_code": "CAT1", "pair_id": "CAT1_25", "pair_number": 25, "variant": "A", "prompt": "¿Qué es un metalenguaje?", "justification_B": "A es definición estándar. B plantea un problema filosófico genuino: esta misma conversación usa el español para hablar sobre el español, lo que viola la separación estricta que Tarski consideraba necesaria para evitar paradojas. La cuestión es si los lenguajes naturales pueden ser su propio metalenguaje.", "prediction": "Acierto en A. En B, respuesta teóricamente informada posible (Tarski está en el corpus lingüístico/filosófico), pero verificar si el modelo reflexiona genuinamente sobre su propia situación comunicativa o reproduce la discusión académica de forma desconectada."}
{"id": "CAT1_25_B", "category_code": "CAT1", "pair_id": "CAT1_25", "pair_number": 25, "variant": "B", "prompt": "¿Está esta conversación usando el español como lenguaje o como metalenguaje? ¿Puede una conversación ser simultáneamente en el lenguaje y sobre el lenguaje? ¿Qué implicaciones tiene esto para la distinción lenguaje/metalenguaje de Tarski?", "justification_B": "A es definición estándar. B plantea un problema filosófico genuino: esta misma conversación usa el español para hablar sobre el español, lo que viola la separación estricta que Tarski consideraba necesaria para evitar paradojas. La cuestión es si los lenguajes naturales pueden ser su propio metalenguaje.", "prediction": "Acierto en A. En B, respuesta teóricamente informada posible (Tarski está en el corpus lingüístico/filosófico), pero verificar si el modelo reflexiona genuinamente sobre su propia situación comunicativa o reproduce la discusión académica de forma desconectada."}
{"id": "CAT1_26_A", "category_code": "CAT1", "pair_id": "CAT1_26", "pair_number": 26, "variant": "A", "prompt": "Traduce «The cat is on the mat» al español.", "justification_B": "A es traducción trivial. B requiere diseño lingüístico: crear un sistema formal coherente (reglas que no se contradigan), aplicarlo (traducción consistente), y demostrar comprensión de la gramaticalidad (producir una violación y explicarla). Es competencia lingüística formal productiva.", "prediction": "Acierto en A. En B, resultado revelador: el modelo generará un «idioma» pero verificar consistencia interna: ¿las reglas se aplican uniformemente en la traducción? ¿La oración agramatical viola realmente la regla citada? La coherencia interna del sistema inventado es el test crítico."}
{"id": "CAT1_26_B", "category_code": "CAT1", "pair_id": "CAT1_26", "pair_number": 26, "variant": "B", "prompt": "Inventa un idioma con 5 reglas gramaticales explícitas, un vocabulario de 10 palabras, y traduce «El gato negro persigue al ratón blanco por la casa» a ese idioma. Luego da un ejemplo de oración agramatical en tu idioma y explica qué regla viola.", "justification_B": "A es traducción trivial. B requiere diseño lingüístico: crear un sistema formal coherente (reglas que no se contradigan), aplicarlo (traducción consistente), y demostrar comprensión de la gramaticalidad (producir una violación y explicarla). Es competencia lingüística formal productiva.", "prediction": "Acierto en A. En B, resultado revelador: el modelo generará un «idioma» pero verificar consistencia interna: ¿las reglas se aplican uniformemente en la traducción? ¿La oración agramatical viola realmente la regla citada? La coherencia interna del sistema inventado es el test crítico."}
{"id": "CAT1_27_A", "category_code": "CAT1", "pair_id": "CAT1_27", "pair_number": 27, "variant": "A", "prompt": "¿Qué es un orden SOV (sujeto-objeto-verbo)?", "justification_B": "A es definición tipológica estándar. B requiere aplicar simultáneamente tres parámetros tipológicos (orden, adposiciones, caso) a una oración con cláusula relativa y ditransitivo. Es tipología lingüística aplicada, no solo definida.", "prediction": "Acierto en A. En B, errores probables en la aplicación consistente del ergativo-absolutivo con ditransitivos (caso particularmente complejo). La combinación de tres parámetros simultáneos excede la reproducción de patrones."}
{"id": "CAT1_27_B", "category_code": "CAT1", "pair_id": "CAT1_27", "pair_number": 27, "variant": "B", "prompt": "Dado un idioma ficticio con orden OSV, posposiciones (en lugar de preposiciones), y marcación de caso ergativo-absolutivo, traduce: «La mujer que vio al niño le dio el libro». Explica cada decisión.", "justification_B": "A es definición tipológica estándar. B requiere aplicar simultáneamente tres parámetros tipológicos (orden, adposiciones, caso) a una oración con cláusula relativa y ditransitivo. Es tipología lingüística aplicada, no solo definida.", "prediction": "Acierto en A. En B, errores probables en la aplicación consistente del ergativo-absolutivo con ditransitivos (caso particularmente complejo). La combinación de tres parámetros simultáneos excede la reproducción de patrones."}
{"id": "CAT1_28_A", "category_code": "CAT1", "pair_id": "CAT1_28", "pair_number": 28, "variant": "A", "prompt": "¿Qué es la recursividad en la gramática?", "justification_B": "A es definición lingüística (auto-inserción de constituyentes). B requiere razonamiento contrafactual sobre la estructura del lenguaje: ¿qué capacidad expresiva se pierde sin recursividad? Conecta con el debate Everett/Chomsky sobre pirahã y con la tesis de la recursividad como propiedad definitoria del lenguaje humano.", "prediction": "Acierto en A. En B, respuesta informada posible (el debate es canónico) pero verificar si los tres ejemplos son genuinamente inexpresables sin recursividad o si son reconvertibles. La manipulación contrafactual del sistema es más difícil que describir el sistema."}
{"id": "CAT1_28_B", "category_code": "CAT1", "pair_id": "CAT1_28", "pair_number": 28, "variant": "B", "prompt": "Si el español perdiera la recursividad y solo permitiera oraciones de máximo una cláusula, ¿qué se podría y qué no se podría expresar? Pon tres ejemplos de conceptos que requerirían múltiples oraciones no recursivas para expresarse.", "justification_B": "A es definición lingüística (auto-inserción de constituyentes). B requiere razonamiento contrafactual sobre la estructura del lenguaje: ¿qué capacidad expresiva se pierde sin recursividad? Conecta con el debate Everett/Chomsky sobre pirahã y con la tesis de la recursividad como propiedad definitoria del lenguaje humano.", "prediction": "Acierto en A. En B, respuesta informada posible (el debate es canónico) pero verificar si los tres ejemplos son genuinamente inexpresables sin recursividad o si son reconvertibles. La manipulación contrafactual del sistema es más difícil que describir el sistema."}
{"id": "CAT1_29_A", "category_code": "CAT1", "pair_id": "CAT1_29", "pair_number": 29, "variant": "A", "prompt": "¿Qué es una gramática generativa?", "justification_B": "A es definición (Chomsky). B requiere construir un formalismo que genere exactamente un conjunto finito de oraciones: es un ejercicio clásico de lingüística computacional. Requiere representación explícita de reglas, concordancia de género, y demostración de que la concordancia bloquea lo agramatical.", "prediction": "Acierto en A. En B, posible acierto parcial (gramáticas libres de contexto son conocidas), pero verificar: ¿la gramática genera exactamente esas tres y nada más? ¿La explicación de la concordancia es formal o informal?"}
{"id": "CAT1_29_B", "category_code": "CAT1", "pair_id": "CAT1_29", "pair_number": 29, "variant": "B", "prompt": "Escribe las reglas de una gramática libre de contexto (en notación formal) que genere exactamente las siguientes tres oraciones y ninguna más: «El gato duerme», «La gata come pescado», «El gato come ratones». Explica por qué tu gramática no genera *«La gato duerme».", "justification_B": "A es definición (Chomsky). B requiere construir un formalismo que genere exactamente un conjunto finito de oraciones: es un ejercicio clásico de lingüística computacional. Requiere representación explícita de reglas, concordancia de género, y demostración de que la concordancia bloquea lo agramatical.", "prediction": "Acierto en A. En B, posible acierto parcial (gramáticas libres de contexto son conocidas), pero verificar: ¿la gramática genera exactamente esas tres y nada más? ¿La explicación de la concordancia es formal o informal?"}
{"id": "CAT1_30_A", "category_code": "CAT1", "pair_id": "CAT1_30", "pair_number": 30, "variant": "A", "prompt": "¿Qué es la competencia lingüística según Chomsky?", "justification_B": "A es definición estándar. B es una prueba metaexperimental: (a) es el estímulo clásico de Chomsky para separar gramaticalidad y significado; (b) es una permutación agramatical. (c)–(d) replican el patrón con un estímulo no canónico (gemelo no famoso) para controlar memorización. El test real es si el modelo puede justificar su juicio con reglas explícitas y consistentes, no con plausibilidad.", "prediction": "Acierto en A. En B, acierto probable en (a) y (b). En (c)–(d), el juicio puede volverse inestable si depende de familiaridad superficial. La explicación meta-cognitiva tenderá a declarar «reglas» (por alineación), aunque el comportamiento sugiera heurística distribucional."}
{"id": "CAT1_30_B", "category_code": "CAT1", "pair_id": "CAT1_30", "pair_number": 30, "variant": "B", "prompt": "Si tú (el LLM) tienes competencia lingüística en el sentido de Chomsky, deberías poder juzgar la gramaticalidad de oraciones que nunca has «visto». Juzga: (a) «Colorless green ideas sleep furiously». (b) «Furiously sleep ideas green colorless». (c) «Silent purple dreams argue politely». (d) «Politely argue dreams purple silent». ¿Estás juzgando por reglas o por familiaridad distribucional? Explica tu criterio.", "justification_B": "A es definición estándar. B es una prueba metaexperimental: (a) es el estímulo clásico de Chomsky para separar gramaticalidad y significado; (b) es una permutación agramatical. (c)–(d) replican el patrón con un estímulo no canónico (gemelo no famoso) para controlar memorización. El test real es si el modelo puede justificar su juicio con reglas explícitas y consistentes, no con plausibilidad.", "prediction": "Acierto en A. En B, acierto probable en (a) y (b). En (c)–(d), el juicio puede volverse inestable si depende de familiaridad superficial. La explicación meta-cognitiva tenderá a declarar «reglas» (por alineación), aunque el comportamiento sugiera heurística distribucional."}
